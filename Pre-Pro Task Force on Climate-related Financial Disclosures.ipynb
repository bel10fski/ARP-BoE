{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-Processing Task Force on Climate-related Financial Disclosures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This script demonstrates the pre-processing of TCF disclosures for two insurance companies, Travelers Cos (TRV) and St. James's Place, preparing them for further NLP analysis. Task Force on Climate-related Financial Disclosures, provide detailed information on how companies are addressing climate-related risks and opportunities. The transcripts were downloaded from each company's website. Their pre-processing is intricate due to the varied formats and detailed nature of the disclosures, necessitating meticulous handling to ensure data consistency for subsequent analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import fnmatch\n",
    "import PyPDF2\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import spacy\n",
    "from nltk.corpus import words\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking for TCFD Reports in Company Directories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code defines a function to search for Task Force on Climate-related Financial Disclosures (TCFD) reports within a specified base directory. It looks through directories for banks and insurers, specifically searching for PDF files containing \"tcfd report\" in their names. Some companies include their TCFD reports inside their annual reports, but this script specifically searches for tailored TCFD reports to ensure focused and relevant data collection. The results are returned in a dictionary structure, organized by sector and company."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sector: Insurers, Company: ST. JAMES place\n",
      "  ARP BOE\\Insurers\\ST. JAMES place\\TCFD\\sjp-tcfd-report-april2020.pdf\n",
      "  ARP BOE\\Insurers\\ST. JAMES place\\TCFD\\sjp-tcfd-report-april2021.pdf\n",
      "  ARP BOE\\Insurers\\ST. JAMES place\\TCFD\\SJP_TCFD_2023.pdf\n",
      "  ARP BOE\\Insurers\\ST. JAMES place\\TCFD\\SJP_TCFD_Report_2022.pdf\n",
      "Sector: Insurers, Company: Traveler Cos TRV\n",
      "  ARP BOE\\Insurers\\Traveler Cos TRV\\TCFD\\Travelers_TCFDReport2019.pdf\n",
      "  ARP BOE\\Insurers\\Traveler Cos TRV\\TCFD\\Travelers_TCFDReport2020.pdf\n",
      "  ARP BOE\\Insurers\\Traveler Cos TRV\\TCFD\\Travelers_TCFDReport2021.pdf\n",
      "  ARP BOE\\Insurers\\Traveler Cos TRV\\TCFD\\Travelers_TCFDReport2022.pdf\n",
      "  ARP BOE\\Insurers\\Traveler Cos TRV\\TCFD\\Travelers_TCFDReport2023.pdf\n"
     ]
    }
   ],
   "source": [
    "def check_tcfd_reports(base_dir):\n",
    "    results = {}\n",
    "    for sector in [\"Banks\", \"Insurers\"]:\n",
    "        sector_path = os.path.join(base_dir, sector)\n",
    "        if not os.path.isdir(sector_path):\n",
    "            continue\n",
    "        \n",
    "        companies = os.listdir(sector_path)\n",
    "        for company in companies:\n",
    "            company_path = os.path.join(sector_path, company)\n",
    "            if not os.path.isdir(company_path):\n",
    "                continue\n",
    "            \n",
    "            tcfd_path = os.path.join(company_path, \"TCFD\")\n",
    "            if not os.path.isdir(tcfd_path):\n",
    "                continue\n",
    "            \n",
    "            # Look for PDF files with \"tcfd report\" in their name (case insensitive)\n",
    "            for root, dirs, files in os.walk(tcfd_path):\n",
    "                for file in files:\n",
    "                    if file.lower().endswith(\".pdf\") and fnmatch.fnmatch(file.lower(), \"*tcfd*.pdf\"):\n",
    "                        if sector not in results:\n",
    "                            results[sector] = {}\n",
    "                        if company not in results[sector]:\n",
    "                            results[sector][company] = []\n",
    "                        results[sector][company].append(os.path.join(root, file))\n",
    "    \n",
    "    return results\n",
    "\n",
    "base_dir = 'ARP BOE'\n",
    "report_files = check_tcfd_reports(base_dir)\n",
    "for sector, companies in report_files.items():\n",
    "    for company, files in companies.items():\n",
    "        print(f\"Sector: {sector}, Company: {company}\")\n",
    "        for file in files:\n",
    "            print(f\"  {file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting text out of the PDFs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved text for ARP BOE\\Insurers\\Traveler Cos TRV\\TCFD\\Travelers_TCFDReport2019.pdf to Example TCFD Texts\\Traveler Cos TRV\\Travelers_TCFDReport2019.txt\n",
      "Saved text for ARP BOE\\Insurers\\Traveler Cos TRV\\TCFD\\Travelers_TCFDReport2020.pdf to Example TCFD Texts\\Traveler Cos TRV\\Travelers_TCFDReport2020.txt\n",
      "Saved text for ARP BOE\\Insurers\\Traveler Cos TRV\\TCFD\\Travelers_TCFDReport2021.pdf to Example TCFD Texts\\Traveler Cos TRV\\Travelers_TCFDReport2021.txt\n",
      "Saved text for ARP BOE\\Insurers\\Traveler Cos TRV\\TCFD\\Travelers_TCFDReport2022.pdf to Example TCFD Texts\\Traveler Cos TRV\\Travelers_TCFDReport2022.txt\n",
      "Saved text for ARP BOE\\Insurers\\Traveler Cos TRV\\TCFD\\Travelers_TCFDReport2023.pdf to Example TCFD Texts\\Traveler Cos TRV\\Travelers_TCFDReport2023.txt\n",
      "Saved text for ARP BOE\\Insurers\\ST. JAMES place\\TCFD\\sjp-tcfd-report-april2020.pdf to Example TCFD Texts\\ST. JAMES place\\sjp-tcfd-report-april2020.txt\n",
      "Saved text for ARP BOE\\Insurers\\ST. JAMES place\\TCFD\\sjp-tcfd-report-april2021.pdf to Example TCFD Texts\\ST. JAMES place\\sjp-tcfd-report-april2021.txt\n",
      "Saved text for ARP BOE\\Insurers\\ST. JAMES place\\TCFD\\SJP_TCFD_2023.pdf to Example TCFD Texts\\ST. JAMES place\\SJP_TCFD_2023.txt\n",
      "Saved text for ARP BOE\\Insurers\\ST. JAMES place\\TCFD\\SJP_TCFD_Report_2022.pdf to Example TCFD Texts\\ST. JAMES place\\SJP_TCFD_Report_2022.txt\n"
     ]
    }
   ],
   "source": [
    "# Traverses directories, extracts TCFD PDF text and saves as .txt files.\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    text = \"\"\n",
    "    try:\n",
    "        with open(pdf_path, 'rb') as file:\n",
    "            reader = PyPDF2.PdfReader(file)\n",
    "            if reader.is_encrypted:\n",
    "                reader.decrypt('')\n",
    "            for page_num in range(len(reader.pages)):\n",
    "                page = reader.pages[page_num]\n",
    "                text += page.extract_text()\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading {pdf_path}: {e}\")\n",
    "    return text\n",
    "\n",
    "def traverse_and_extract_text_for_companies(root_dir, output_dir, companies, max_files_per_folder=10):\n",
    "    total_size = 0\n",
    "\n",
    "    for sector in companies:\n",
    "        for company in companies[sector]:\n",
    "            tcfd_path = os.path.join(root_dir, sector, company, \"TCFD\")\n",
    "            if os.path.isdir(tcfd_path):\n",
    "                company_output_dir = os.path.join(output_dir, company)\n",
    "                os.makedirs(company_output_dir, exist_ok=True)\n",
    "                \n",
    "                file_count = 0\n",
    "                for root, dirs, files in os.walk(tcfd_path):\n",
    "                    for file in files:\n",
    "                        if file.lower().endswith(\".pdf\") and \"tcfd\" in file.lower() and file_count < max_files_per_folder:\n",
    "                            pdf_path = os.path.join(root, file)\n",
    "                            file_size = os.path.getsize(pdf_path)\n",
    "                            text = extract_text_from_pdf(pdf_path)\n",
    "\n",
    "                            if text:\n",
    "                                # Save the text as a .txt file\n",
    "                                output_file = os.path.join(company_output_dir, f\"{os.path.splitext(file)[0]}.txt\")\n",
    "                                with open(output_file, 'w', encoding='utf-8') as txt_file:\n",
    "                                    txt_file.write(text)\n",
    "                                print(f\"Saved text for {pdf_path} to {output_file}\")\n",
    "\n",
    "                                total_size += file_size\n",
    "                                file_count += 1\n",
    "\n",
    "                            if file_count >= max_files_per_folder:\n",
    "                                break\n",
    "\n",
    "    return total_size\n",
    "\n",
    "# Root directory path\n",
    "root_dir = \"ARP BOE\"\n",
    "# Output directory path\n",
    "output_dir = \"Example TCFD Texts\"\n",
    "\n",
    "# Create output directory if it doesn't exist\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "# Specified companies\n",
    "companies = {\n",
    "    \"Insurers\": [\"Traveler Cos TRV\", \"ST. JAMES place\"],\n",
    "}\n",
    "\n",
    "total_size = traverse_and_extract_text_for_companies(root_dir, output_dir, companies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tailored Cleaning and Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script demonstrates the cleaning and pre-processing of the TCFDs for Travelers Cos (TRV) and St. James's Place. The script performs several tasks:\n",
    "\n",
    "- Download Necessary NLTK Data: Ensures that the necessary stopwords and English words are downloaded from NLTK.\n",
    "- Define Cleaning Functions: Includes functions to clean the text by removing headers, footers, special characters, non-English words and unnecessary spaces.\n",
    "- Specific Cleaning for Each Company: Custom cleaning functions are tailored for the unique formats of the disclosures from each company.\n",
    "- Save Cleaned Texts: The cleaned text files are saved to specified output directories, maintaining the directory structure from the input."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Traveler Cos TRV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\dimi3\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed Travelers_TCFDReport2019.txt and saved to Cleaned TCFD Texts/Traveler Cos TRV\\cleaned_Travelers_TCFDReport2019.txt\n",
      "Processed Travelers_TCFDReport2020.txt and saved to Cleaned TCFD Texts/Traveler Cos TRV\\cleaned_Travelers_TCFDReport2020.txt\n",
      "Processed Travelers_TCFDReport2021.txt and saved to Cleaned TCFD Texts/Traveler Cos TRV\\cleaned_Travelers_TCFDReport2021.txt\n",
      "Processed Travelers_TCFDReport2022.txt and saved to Cleaned TCFD Texts/Traveler Cos TRV\\cleaned_Travelers_TCFDReport2022.txt\n",
      "Processed Travelers_TCFDReport2023.txt and saved to Cleaned TCFD Texts/Traveler Cos TRV\\cleaned_Travelers_TCFDReport2023.txt\n"
     ]
    }
   ],
   "source": [
    "# Ensure the NLTK words corpus is downloaded\n",
    "nltk.download('words')\n",
    "english_vocab = set(words.words())\n",
    "\n",
    "# Directory containing the text files\n",
    "input_dir = \"Example TCFD Texts/Traveler Cos TRV\"\n",
    "output_directory = 'Cleaned TCFD Texts/Traveler Cos TRV'\n",
    "\n",
    "# Create the output directory if it doesn't exist\n",
    "if not os.path.exists(output_directory):\n",
    "    os.makedirs(output_directory)\n",
    "\n",
    "# Define a function to clean the text\n",
    "def clean_text(text, year):\n",
    "    # Remove specific phrase with year\n",
    "    text = re.sub(rf\"Travelers Task Force on Climate-related Financial Disclosures Report\\s*{year}\\s*\\d*\", \"\", text)\n",
    "\n",
    "    # Remove numbered list items ending with a dot (e.g., \"3.\" but not \"3.1\")\n",
    "    text = re.sub(r'\\b\\d+\\.(?!\\d)', \"\", text)\n",
    "\n",
    "    # Remove bullet points\n",
    "    text = re.sub(r'•', \"\", text)\n",
    "\n",
    "    # Remove text starting from \"Important Legal Information\"\n",
    "    text = re.split(r\"Important Legal Information\", text)[0]\n",
    "\n",
    "    # Remove \"Figure\" followed by number and dot or if it is alone in a row\n",
    "    text = re.sub(r'Figure(\\s*\\d+\\.)?', \"\", text)\n",
    "\n",
    "    # Remove bracketed numbers like [1]\n",
    "    text = re.sub(r'\\[\\d+\\]', \"\", text)\n",
    "\n",
    "    # Remove inline numbers within words (e.g., \"1kill\")\n",
    "    text = re.sub(r'(?<=\\D)\\d+(?=\\D)', \"\", text)\n",
    "\n",
    "    # Normalize spaced letters (e.g., e l e c t r i c v e h i c l e to electric vehicle)\n",
    "    text = re.sub(r'\\b(?:[a-zA-Z]\\s)+[a-zA-Z]\\b', lambda m: m.group(0).replace(' ', ''), text)\n",
    "\n",
    "    # Split text into lines\n",
    "    lines = text.splitlines()\n",
    "\n",
    "    # Remove lines containing \".lnum\"\n",
    "    lines = [line for line in lines if \".lnum\" not in line]\n",
    "\n",
    "    # Remove lines based on year\n",
    "    if year == \"2021\":\n",
    "        lines = lines[22:]\n",
    "    elif year == \"2022\":\n",
    "        lines = lines[21:]\n",
    "    elif year == \"2023\":\n",
    "        lines = lines[21:]\n",
    "    else:  # For other years like 2019 and 2020\n",
    "        lines = lines[4:]\n",
    "\n",
    "    # Filter non-English words and special characters\n",
    "    def filter_line(line):\n",
    "        filtered_words = []\n",
    "        for word in re.findall(r'\\b\\w+\\b', line):\n",
    "            if word.lower() in english_vocab or word.isdigit():\n",
    "                filtered_words.append(word)\n",
    "        return \" \".join(filtered_words)\n",
    "\n",
    "    # Apply filter to each line to keep structure\n",
    "    filtered_lines = [filter_line(line) for line in lines]\n",
    "\n",
    "    # Remove empty lines\n",
    "    filtered_lines = [line for line in filtered_lines if line.strip()]\n",
    "\n",
    "    # Join lines back into text\n",
    "    text = \"\\n\".join(filtered_lines)\n",
    "\n",
    "    return text\n",
    "\n",
    "# Process each text file in the directory\n",
    "for filename in os.listdir(input_dir):\n",
    "    if filename.endswith(\".txt\"):\n",
    "        file_path = os.path.join(input_dir, filename)\n",
    "\n",
    "        # Extract the year from the filename (assuming the format is consistent)\n",
    "        year_match = re.search(r'\\d{4}', filename)\n",
    "        if year_match:\n",
    "            year = year_match.group(0)\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "        # Read the file\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            text = file.read()\n",
    "\n",
    "        # Clean the text\n",
    "        cleaned_text = clean_text(text, year)\n",
    "\n",
    "        # Save the cleaned text back to a file\n",
    "        cleaned_file_path = os.path.join(output_directory, f\"cleaned_{filename}\")\n",
    "        with open(cleaned_file_path, 'w', encoding='utf-8') as file:\n",
    "            file.write(cleaned_text)\n",
    "\n",
    "        print(f\"Processed {filename} and saved to {cleaned_file_path}\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### St. James Place"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed sjp-tcfd-report-april2020.txt and saved to Cleaned TCFD Texts/ST. JAMES place\\cleaned_sjp-tcfd-report-april2020.txt\n",
      "Processed sjp-tcfd-report-april2021.txt and saved to Cleaned TCFD Texts/ST. JAMES place\\cleaned_sjp-tcfd-report-april2021.txt\n",
      "Processed SJP_TCFD_2023.txt and saved to Cleaned TCFD Texts/ST. JAMES place\\cleaned_SJP_TCFD_2023.txt\n",
      "Processed SJP_TCFD_Report_2022.txt and saved to Cleaned TCFD Texts/ST. JAMES place\\cleaned_SJP_TCFD_Report_2022.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\dimi3\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Ensure the NLTK words corpus is downloaded\n",
    "nltk.download('words')\n",
    "english_vocab = set(words.words())\n",
    "\n",
    "# Directory containing the text files\n",
    "input_dir = \"Example TCFD Texts/ST. JAMES place\"\n",
    "output_directory = 'Cleaned TCFD Texts/ST. JAMES place'\n",
    "\n",
    "# Create the output directory if it doesn't exist\n",
    "if not os.path.exists(output_directory):\n",
    "    os.makedirs(output_directory)\n",
    "\n",
    "# Define a function to clean the text\n",
    "def clean_text(text, year):\n",
    "    # Remove specific phrase with year\n",
    "    text = re.sub(rf\"St. James’s Place TCFD Report\\s*{year}\\s*\\d*\", \"\", text)\n",
    "\n",
    "    # Remove specific sections for 2020\n",
    "    if year == \"2020\":\n",
    "        text = re.sub(r'\\b(?:Introduction|Governance|Strategy|Risk Management|Metrics & Targets|Glossary)\\b', \"\", text)\n",
    "\n",
    "    # Remove numbered list items ending with a dot (e.g., \"3.\" but not \"3.1\")\n",
    "    text = re.sub(r'\\b\\d+\\.(?!\\d)', \"\", text)\n",
    "\n",
    "    # Remove bullet points and specific characters\n",
    "    text = re.sub(r'•||l|©', \"\", text)\n",
    "\n",
    "    # Normalize spaced letters (e.g., e l e c t r i c v e h i c l e to electric vehicle)\n",
    "    text = re.sub(r'\\b(?:[a-zA-Z]\\s)+[a-zA-Z]\\b', lambda m: m.group(0).replace(' ', ''), text)\n",
    "\n",
    "    # Split text into lines\n",
    "    lines = text.splitlines()\n",
    "\n",
    "    # Remove first 60 and last 80 rows\n",
    "    if len(lines) > 140:\n",
    "        lines = lines[61:-80]\n",
    "\n",
    "    # Define patterns for removal\n",
    "    patterns = [\n",
    "        r'^\\s*[a-zA-Z0-9]\\)\\s*',  # Lines starting with \"c)\" or \"1)\"\n",
    "        r'^\\s*#\\d+',              # Lines starting with \"#3\"\n",
    "        r'^\\s*Scope\\b.*',         # Lines starting with \"Scope\"\n",
    "        r'^\\s*[%$\\-].*',          # Lines starting with \"%\", \"$\", or \"-\"\n",
    "        r'^\\s*Pages\\s*\\d+–\\d+\\s*$', # Lines like \"Pages 44–45\"\n",
    "        r'^\\s*Figure(\\s*\\d+\\.)?$', # \"Figure\" alone or followed by number\n",
    "    ]\n",
    "\n",
    "    # Filter non-English words and special characters\n",
    "    def filter_line(line):\n",
    "        filtered_words = []\n",
    "        for word in re.findall(r'\\b\\w+\\b', line):\n",
    "            if word.lower() in english_vocab or word.isdigit():\n",
    "                filtered_words.append(word)\n",
    "        return \" \".join(filtered_words)\n",
    "\n",
    "    # Apply filters to each line\n",
    "    filtered_lines = []\n",
    "    for line in lines:\n",
    "        # Remove lines with only numbers, only letters, or combinations like 'S 0 1'\n",
    "        if (re.match(r'^[0-9\\s]+$', line.strip()) or \n",
    "            re.match(r'^[a-zA-Z\\s]+$', line.strip()) or \n",
    "            re.match(r'^[a-zA-Z0-9\\s]+$', line.strip())):\n",
    "            continue\n",
    "        \n",
    "        # Only keep lines that do not match removal criteria\n",
    "        if not any(re.match(pattern, line) for pattern in patterns):\n",
    "            filtered_line = filter_line(line)\n",
    "            if filtered_line:\n",
    "                filtered_lines.append(filtered_line)\n",
    "\n",
    "    # Join lines back into text\n",
    "    text = \"\\n\".join(filtered_lines)\n",
    "\n",
    "    return text\n",
    "\n",
    "# Process each text file in the directory\n",
    "for filename in os.listdir(input_dir):\n",
    "    if filename.endswith(\".txt\"):\n",
    "        file_path = os.path.join(input_dir, filename)\n",
    "\n",
    "        # Extract the year from the filename (assuming the format is consistent)\n",
    "        year_match = re.search(r'\\d{4}', filename)\n",
    "        if year_match:\n",
    "            year = year_match.group(0)\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "        # Read the file\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            text = file.read()\n",
    "\n",
    "        # Clean the text\n",
    "        cleaned_text = clean_text(text, year)\n",
    "\n",
    "        # Save the cleaned text back to a file\n",
    "        cleaned_file_path = os.path.join(output_directory, f\"cleaned_{filename}\")\n",
    "        with open(cleaned_file_path, 'w', encoding='utf-8') as file:\n",
    "            file.write(cleaned_text)\n",
    "\n",
    "        print(f\"Processed {filename} and saved to {cleaned_file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Organizing Cleaned TCFD Text Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The script extracts and organizes cleaned TCFD text data, preparing it for further analysis. It performs the following steps:\n",
    "\n",
    "- Data Extraction: Reads the text from each file and extracts the year and company name from the filename and directory structure.\n",
    "- Data Compilation: Compiles the extracted data into a list.\n",
    "- DataFrame Creation: Creates a DataFrame with columns for the file name, year, company name, and text content.\n",
    "- Data Sorting: Converts the 'year' column to integers, handling any non-numeric values, and sorts the DataFrame by company name and year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>year</th>\n",
       "      <th>company_name</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cleaned_sjp-tcfd-report-april2020.txt</td>\n",
       "      <td>2020</td>\n",
       "      <td>ST. JAMES place</td>\n",
       "      <td>Committee s\\nof the Net\\nSt s Pace Report 2020...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cleaned_sjp-tcfd-report-april2021.txt</td>\n",
       "      <td>2021</td>\n",
       "      <td>ST. JAMES place</td>\n",
       "      <td>46 to our 2021 report\\nto St s Pace Group s re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cleaned_SJP_TCFD_Report_2022.txt</td>\n",
       "      <td>2022</td>\n",
       "      <td>ST. JAMES place</td>\n",
       "      <td>change is fast becoming one\\nour It is a that ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cleaned_SJP_TCFD_2023.txt</td>\n",
       "      <td>2023</td>\n",
       "      <td>ST. JAMES place</td>\n",
       "      <td>approach We are to our\\nwi have a effect over ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cleaned_Travelers_TCFDReport2019.txt</td>\n",
       "      <td>2019</td>\n",
       "      <td>Traveler Cos TRV</td>\n",
       "      <td>Severe weather over the last two have\\nthe of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>cleaned_Travelers_TCFDReport2020.txt</td>\n",
       "      <td>2020</td>\n",
       "      <td>Traveler Cos TRV</td>\n",
       "      <td>Severe weather over the last two have\\nthe of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>cleaned_Travelers_TCFDReport2021.txt</td>\n",
       "      <td>2021</td>\n",
       "      <td>Traveler Cos TRV</td>\n",
       "      <td>additional uncertainty as to future and Climat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>cleaned_Travelers_TCFDReport2022.txt</td>\n",
       "      <td>2022</td>\n",
       "      <td>Traveler Cos TRV</td>\n",
       "      <td>of climate For example the frequency and or se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>cleaned_Travelers_TCFDReport2023.txt</td>\n",
       "      <td>2023</td>\n",
       "      <td>Traveler Cos TRV</td>\n",
       "      <td>Severe weather over the last two have the\\nof ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               file_name  year      company_name  \\\n",
       "0  cleaned_sjp-tcfd-report-april2020.txt  2020   ST. JAMES place   \n",
       "1  cleaned_sjp-tcfd-report-april2021.txt  2021   ST. JAMES place   \n",
       "2       cleaned_SJP_TCFD_Report_2022.txt  2022   ST. JAMES place   \n",
       "3              cleaned_SJP_TCFD_2023.txt  2023   ST. JAMES place   \n",
       "4   cleaned_Travelers_TCFDReport2019.txt  2019  Traveler Cos TRV   \n",
       "5   cleaned_Travelers_TCFDReport2020.txt  2020  Traveler Cos TRV   \n",
       "6   cleaned_Travelers_TCFDReport2021.txt  2021  Traveler Cos TRV   \n",
       "7   cleaned_Travelers_TCFDReport2022.txt  2022  Traveler Cos TRV   \n",
       "8   cleaned_Travelers_TCFDReport2023.txt  2023  Traveler Cos TRV   \n",
       "\n",
       "                                                text  \n",
       "0  Committee s\\nof the Net\\nSt s Pace Report 2020...  \n",
       "1  46 to our 2021 report\\nto St s Pace Group s re...  \n",
       "2  change is fast becoming one\\nour It is a that ...  \n",
       "3  approach We are to our\\nwi have a effect over ...  \n",
       "4  Severe weather over the last two have\\nthe of ...  \n",
       "5  Severe weather over the last two have\\nthe of ...  \n",
       "6  additional uncertainty as to future and Climat...  \n",
       "7  of climate For example the frequency and or se...  \n",
       "8  Severe weather over the last two have the\\nof ...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Directory containing the cleaned text files\n",
    "input_dir = \"Cleaned TCFD Texts\"\n",
    "\n",
    "# Initialize a list to hold the extracted data\n",
    "extracted_data = []\n",
    "\n",
    "# Iterate over each text file in the directory\n",
    "for company_dir in os.listdir(input_dir):\n",
    "    company_path = os.path.join(input_dir, company_dir)\n",
    "    if os.path.isdir(company_path):\n",
    "        for filename in os.listdir(company_path):\n",
    "            if filename.endswith(\".txt\"):\n",
    "                file_path = os.path.join(company_path, filename)\n",
    "                with open(file_path, 'r', encoding='utf-8') as file:\n",
    "                    text = file.read()\n",
    "                    \n",
    "                    # Extract the year and company name from the filename\n",
    "                    year_match = re.search(r'\\d{4}', filename)\n",
    "                    year = year_match.group(0) if year_match else None\n",
    "                    company_name = company_dir.replace(\"_\", \" \")\n",
    "\n",
    "                    extracted_data.append([filename, year, company_name, text])\n",
    "\n",
    "# Create a DataFrame with the extracted data\n",
    "df_horizontal = pd.DataFrame(extracted_data, columns=['file_name', 'year', 'company_name', 'text'])\n",
    "\n",
    "# Convert 'year' column to integer for sorting, handling None values\n",
    "df_horizontal['year'] = pd.to_numeric(df_horizontal['year'], errors='coerce')\n",
    "\n",
    "# Sort the DataFrame by 'company_name' and then by 'year'\n",
    "df_horizontal = df_horizontal.sort_values(by=['company_name', 'year']).reset_index(drop=True)\n",
    "\n",
    "# Print the DataFrame\n",
    "pd.set_option('display.max_columns', None)\n",
    "df_horizontal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Cleaning and Post-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The script loads a spaCy model and performs text cleaning and post-processing. It includes functions to remove unwanted characters, stop words, numbers, punctuation, and to lemmatize the text. The cleaned text is stored in a new column in the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:07<00:00,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>year</th>\n",
       "      <th>company_name</th>\n",
       "      <th>text</th>\n",
       "      <th>text_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cleaned_sjp-tcfd-report-april2020.txt</td>\n",
       "      <td>2020</td>\n",
       "      <td>ST. JAMES place</td>\n",
       "      <td>Committee s\\nof the Net\\nSt s Pace Report 2020...</td>\n",
       "      <td>Committee s Net St s Pace Report worth year ti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cleaned_sjp-tcfd-report-april2021.txt</td>\n",
       "      <td>2021</td>\n",
       "      <td>ST. JAMES place</td>\n",
       "      <td>46 to our 2021 report\\nto St s Pace Group s re...</td>\n",
       "      <td>report St s Pace Group s report wi take action...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cleaned_SJP_TCFD_Report_2022.txt</td>\n",
       "      <td>2022</td>\n",
       "      <td>ST. JAMES place</td>\n",
       "      <td>change is fast becoming one\\nour It is a that ...</td>\n",
       "      <td>change fast address Foster Director Business i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cleaned_SJP_TCFD_2023.txt</td>\n",
       "      <td>2023</td>\n",
       "      <td>ST. JAMES place</td>\n",
       "      <td>approach We are to our\\nwi have a effect over ...</td>\n",
       "      <td>approach wi effect time Maria Spooner Director...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cleaned_Travelers_TCFDReport2019.txt</td>\n",
       "      <td>2019</td>\n",
       "      <td>Traveler Cos TRV</td>\n",
       "      <td>Severe weather over the last two have\\nthe of ...</td>\n",
       "      <td>severe weather future climate climate add freq...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>cleaned_Travelers_TCFDReport2020.txt</td>\n",
       "      <td>2020</td>\n",
       "      <td>Traveler Cos TRV</td>\n",
       "      <td>Severe weather over the last two have\\nthe of ...</td>\n",
       "      <td>severe weather future climate climate add freq...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>cleaned_Travelers_TCFDReport2021.txt</td>\n",
       "      <td>2021</td>\n",
       "      <td>Traveler Cos TRV</td>\n",
       "      <td>additional uncertainty as to future and Climat...</td>\n",
       "      <td>additional uncertainty future climate governme...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>cleaned_Travelers_TCFDReport2022.txt</td>\n",
       "      <td>2022</td>\n",
       "      <td>Traveler Cos TRV</td>\n",
       "      <td>of climate For example the frequency and or se...</td>\n",
       "      <td>climate example frequency severity hurricane t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>cleaned_Travelers_TCFDReport2023.txt</td>\n",
       "      <td>2023</td>\n",
       "      <td>Traveler Cos TRV</td>\n",
       "      <td>Severe weather over the last two have the\\nof ...</td>\n",
       "      <td>severe weather climate example frequency sever...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               file_name  year      company_name  \\\n",
       "0  cleaned_sjp-tcfd-report-april2020.txt  2020   ST. JAMES place   \n",
       "1  cleaned_sjp-tcfd-report-april2021.txt  2021   ST. JAMES place   \n",
       "2       cleaned_SJP_TCFD_Report_2022.txt  2022   ST. JAMES place   \n",
       "3              cleaned_SJP_TCFD_2023.txt  2023   ST. JAMES place   \n",
       "4   cleaned_Travelers_TCFDReport2019.txt  2019  Traveler Cos TRV   \n",
       "5   cleaned_Travelers_TCFDReport2020.txt  2020  Traveler Cos TRV   \n",
       "6   cleaned_Travelers_TCFDReport2021.txt  2021  Traveler Cos TRV   \n",
       "7   cleaned_Travelers_TCFDReport2022.txt  2022  Traveler Cos TRV   \n",
       "8   cleaned_Travelers_TCFDReport2023.txt  2023  Traveler Cos TRV   \n",
       "\n",
       "                                                text  \\\n",
       "0  Committee s\\nof the Net\\nSt s Pace Report 2020...   \n",
       "1  46 to our 2021 report\\nto St s Pace Group s re...   \n",
       "2  change is fast becoming one\\nour It is a that ...   \n",
       "3  approach We are to our\\nwi have a effect over ...   \n",
       "4  Severe weather over the last two have\\nthe of ...   \n",
       "5  Severe weather over the last two have\\nthe of ...   \n",
       "6  additional uncertainty as to future and Climat...   \n",
       "7  of climate For example the frequency and or se...   \n",
       "8  Severe weather over the last two have the\\nof ...   \n",
       "\n",
       "                                          text_clean  \n",
       "0  Committee s Net St s Pace Report worth year ti...  \n",
       "1  report St s Pace Group s report wi take action...  \n",
       "2  change fast address Foster Director Business i...  \n",
       "3  approach wi effect time Maria Spooner Director...  \n",
       "4  severe weather future climate climate add freq...  \n",
       "5  severe weather future climate climate add freq...  \n",
       "6  additional uncertainty future climate governme...  \n",
       "7  climate example frequency severity hurricane t...  \n",
       "8  severe weather climate example frequency sever...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load spaCy model\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "# Function to clean text in the text_series\n",
    "def clean_text(text_series):\n",
    "    # Convert text_series df to list\n",
    "    text_list = text_series.to_list()\n",
    "\n",
    "    # Remove whitespaces and trailing spaces\n",
    "    def remove_whitespace(text):\n",
    "        pattern = re.compile(r'\\s+')\n",
    "        without_whitespace = re.sub(pattern, ' ', text)\n",
    "        text = without_whitespace.replace('?', ' ? ').replace(')', ') ')\n",
    "        text = text.strip()\n",
    "        return text\n",
    "\n",
    "    text_list = list(map(lambda x: remove_whitespace(x), text_list))\n",
    "\n",
    "    # Apply NLP pipeline to remove stop words, numbers, and lemmatize the words\n",
    "    cleaned_text_list = []\n",
    "    for text in tqdm(text_list):  # or tqdm.tqdm\n",
    "        doc = nlp(text)\n",
    "        cleaned_text = \" \".join([\n",
    "            token.lemma_\n",
    "            for token in doc\n",
    "            if not token.is_stop\n",
    "            and not token.like_num\n",
    "            and not token.is_punct\n",
    "            and token.is_alpha\n",
    "        ])\n",
    "        cleaned_text_list.append(cleaned_text)\n",
    "    return cleaned_text_list\n",
    "\n",
    "# Function to post-process the DataFrame\n",
    "def post_process(df):\n",
    "    # Create a new column 'text_clean'\n",
    "    df['text_clean'] = df['text']\n",
    "\n",
    "    # Remove unwanted characters and numeric values\n",
    "    df['text_clean'] = df['text_clean'].str.replace(',', '', regex=False)\n",
    "    df['text_clean'] = df['text_clean'].str.replace('.', '', regex=False)\n",
    "    df['text_clean'] = df['text_clean'].str.replace('(', '', regex=False)\n",
    "    df['text_clean'] = df['text_clean'].str.replace(')', '', regex=False)\n",
    "    df['text_clean'] = df['text_clean'].str.replace(r'\\d+\\.\\d+', '', regex=True)\n",
    "    df['text_clean'] = df['text_clean'].str.replace('\\d+', '', regex=True)\n",
    "    df['text_clean'] = df['text_clean'].astype(str)\n",
    "\n",
    "    return df\n",
    "\n",
    "# Assuming df_horizontal is your DataFrame\n",
    "df_horizontal = post_process(df_horizontal)\n",
    "\n",
    "# Clean the 'text_clean' column\n",
    "df_horizontal['text_clean'] = clean_text(df_horizontal['text_clean'])\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "print(df_horizontal['file_name'].nunique())\n",
    "df_horizontal\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Noun Lemmatization of Cleaned TCFDs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code applies lemmatization to extract nouns from the 'text_clean' column using spaCy and stores the results in a new column 'text_noun'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>year</th>\n",
       "      <th>company_name</th>\n",
       "      <th>text</th>\n",
       "      <th>text_clean</th>\n",
       "      <th>text_noun</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cleaned_sjp-tcfd-report-april2020.txt</td>\n",
       "      <td>2020</td>\n",
       "      <td>ST. JAMES place</td>\n",
       "      <td>Committee s\\nof the Net\\nSt s Pace Report 2020...</td>\n",
       "      <td>Committee s Net St s Pace Report worth year ti...</td>\n",
       "      <td>year time commitment term change business repo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cleaned_sjp-tcfd-report-april2021.txt</td>\n",
       "      <td>2021</td>\n",
       "      <td>ST. JAMES place</td>\n",
       "      <td>46 to our 2021 report\\nto St s Pace Group s re...</td>\n",
       "      <td>report St s Pace Group s report wi take action...</td>\n",
       "      <td>report action change business home page report...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cleaned_SJP_TCFD_Report_2022.txt</td>\n",
       "      <td>2022</td>\n",
       "      <td>ST. JAMES place</td>\n",
       "      <td>change is fast becoming one\\nour It is a that ...</td>\n",
       "      <td>change fast address Foster Director Business i...</td>\n",
       "      <td>address introduction statement business parent...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cleaned_SJP_TCFD_2023.txt</td>\n",
       "      <td>2023</td>\n",
       "      <td>ST. JAMES place</td>\n",
       "      <td>approach We are to our\\nwi have a effect over ...</td>\n",
       "      <td>approach wi effect time Maria Spooner Director...</td>\n",
       "      <td>effect time business unit trust manager whist ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cleaned_Travelers_TCFDReport2019.txt</td>\n",
       "      <td>2019</td>\n",
       "      <td>Traveler Cos TRV</td>\n",
       "      <td>Severe weather over the last two have\\nthe of ...</td>\n",
       "      <td>severe weather future climate climate add freq...</td>\n",
       "      <td>weather climate climate severity insurance com...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>cleaned_Travelers_TCFDReport2020.txt</td>\n",
       "      <td>2020</td>\n",
       "      <td>Traveler Cos TRV</td>\n",
       "      <td>Severe weather over the last two have\\nthe of ...</td>\n",
       "      <td>severe weather future climate climate add freq...</td>\n",
       "      <td>weather climate climate severity uncertainty i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>cleaned_Travelers_TCFDReport2021.txt</td>\n",
       "      <td>2021</td>\n",
       "      <td>Traveler Cos TRV</td>\n",
       "      <td>additional uncertainty as to future and Climat...</td>\n",
       "      <td>additional uncertainty future climate governme...</td>\n",
       "      <td>uncertainty climate government catastrophe mod...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>cleaned_Travelers_TCFDReport2022.txt</td>\n",
       "      <td>2022</td>\n",
       "      <td>Traveler Cos TRV</td>\n",
       "      <td>of climate For example the frequency and or se...</td>\n",
       "      <td>climate example frequency severity hurricane t...</td>\n",
       "      <td>example frequency severity wildfire time perio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>cleaned_Travelers_TCFDReport2023.txt</td>\n",
       "      <td>2023</td>\n",
       "      <td>Traveler Cos TRV</td>\n",
       "      <td>Severe weather over the last two have the\\nof ...</td>\n",
       "      <td>severe weather climate example frequency sever...</td>\n",
       "      <td>weather climate example frequency severity wil...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               file_name  year      company_name  \\\n",
       "0  cleaned_sjp-tcfd-report-april2020.txt  2020   ST. JAMES place   \n",
       "1  cleaned_sjp-tcfd-report-april2021.txt  2021   ST. JAMES place   \n",
       "2       cleaned_SJP_TCFD_Report_2022.txt  2022   ST. JAMES place   \n",
       "3              cleaned_SJP_TCFD_2023.txt  2023   ST. JAMES place   \n",
       "4   cleaned_Travelers_TCFDReport2019.txt  2019  Traveler Cos TRV   \n",
       "5   cleaned_Travelers_TCFDReport2020.txt  2020  Traveler Cos TRV   \n",
       "6   cleaned_Travelers_TCFDReport2021.txt  2021  Traveler Cos TRV   \n",
       "7   cleaned_Travelers_TCFDReport2022.txt  2022  Traveler Cos TRV   \n",
       "8   cleaned_Travelers_TCFDReport2023.txt  2023  Traveler Cos TRV   \n",
       "\n",
       "                                                text  \\\n",
       "0  Committee s\\nof the Net\\nSt s Pace Report 2020...   \n",
       "1  46 to our 2021 report\\nto St s Pace Group s re...   \n",
       "2  change is fast becoming one\\nour It is a that ...   \n",
       "3  approach We are to our\\nwi have a effect over ...   \n",
       "4  Severe weather over the last two have\\nthe of ...   \n",
       "5  Severe weather over the last two have\\nthe of ...   \n",
       "6  additional uncertainty as to future and Climat...   \n",
       "7  of climate For example the frequency and or se...   \n",
       "8  Severe weather over the last two have the\\nof ...   \n",
       "\n",
       "                                          text_clean  \\\n",
       "0  Committee s Net St s Pace Report worth year ti...   \n",
       "1  report St s Pace Group s report wi take action...   \n",
       "2  change fast address Foster Director Business i...   \n",
       "3  approach wi effect time Maria Spooner Director...   \n",
       "4  severe weather future climate climate add freq...   \n",
       "5  severe weather future climate climate add freq...   \n",
       "6  additional uncertainty future climate governme...   \n",
       "7  climate example frequency severity hurricane t...   \n",
       "8  severe weather climate example frequency sever...   \n",
       "\n",
       "                                           text_noun  \n",
       "0  year time commitment term change business repo...  \n",
       "1  report action change business home page report...  \n",
       "2  address introduction statement business parent...  \n",
       "3  effect time business unit trust manager whist ...  \n",
       "4  weather climate climate severity insurance com...  \n",
       "5  weather climate climate severity uncertainty i...  \n",
       "6  uncertainty climate government catastrophe mod...  \n",
       "7  example frequency severity wildfire time perio...  \n",
       "8  weather climate example frequency severity wil...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load spaCy model\n",
    "nlp = spacy.load(\"en_core_web_lg\", disable=[\"parser\", \"ner\"])\n",
    "\n",
    "# Lemmatization function\n",
    "def lemmatization(texts, allowed_postags=[\"NOUN\"]):\n",
    "    doc = nlp(texts)\n",
    "    new_text = []\n",
    "    for token in doc:\n",
    "        if token.pos_ in allowed_postags:\n",
    "            new_text.append(token.lemma_)\n",
    "    final = \" \".join(new_text)\n",
    "    return final\n",
    "\n",
    "# Apply lemmatization to the 'text_clean' column\n",
    "df_horizontal['text_noun'] = df_horizontal['text_clean'].apply(lemmatization)\n",
    "\n",
    "# Display the DataFrame\n",
    "pd.set_option('display.max_columns', None)\n",
    "print(df_horizontal['file_name'].nunique())\n",
    "df_horizontal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenizing and Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The script performs detailed text tokenization and filtering on TCFD disclosures. The steps involve defining functions to clean, tokenize text and removing general words that are not useful for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:00<00:00, 11.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>year</th>\n",
       "      <th>company_name</th>\n",
       "      <th>text</th>\n",
       "      <th>text_clean</th>\n",
       "      <th>text_noun</th>\n",
       "      <th>token</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cleaned_sjp-tcfd-report-april2020.txt</td>\n",
       "      <td>2020</td>\n",
       "      <td>ST. JAMES place</td>\n",
       "      <td>Committee s\\nof the Net\\nSt s Pace Report 2020...</td>\n",
       "      <td>Committee s Net St s Pace Report worth year ti...</td>\n",
       "      <td>year time commitment term change business repo...</td>\n",
       "      <td>[year, time, commitment, term, change, busines...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cleaned_sjp-tcfd-report-april2021.txt</td>\n",
       "      <td>2021</td>\n",
       "      <td>ST. JAMES place</td>\n",
       "      <td>46 to our 2021 report\\nto St s Pace Group s re...</td>\n",
       "      <td>report St s Pace Group s report wi take action...</td>\n",
       "      <td>report action change business home page report...</td>\n",
       "      <td>[report, action, change, business, home, page,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cleaned_SJP_TCFD_Report_2022.txt</td>\n",
       "      <td>2022</td>\n",
       "      <td>ST. JAMES place</td>\n",
       "      <td>change is fast becoming one\\nour It is a that ...</td>\n",
       "      <td>change fast address Foster Director Business i...</td>\n",
       "      <td>address introduction statement business parent...</td>\n",
       "      <td>[address, introduction, statement, business, p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cleaned_SJP_TCFD_2023.txt</td>\n",
       "      <td>2023</td>\n",
       "      <td>ST. JAMES place</td>\n",
       "      <td>approach We are to our\\nwi have a effect over ...</td>\n",
       "      <td>approach wi effect time Maria Spooner Director...</td>\n",
       "      <td>effect time business unit trust manager whist ...</td>\n",
       "      <td>[effect, time, business, unit, trust, manager,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cleaned_Travelers_TCFDReport2019.txt</td>\n",
       "      <td>2019</td>\n",
       "      <td>Traveler Cos TRV</td>\n",
       "      <td>Severe weather over the last two have\\nthe of ...</td>\n",
       "      <td>severe weather future climate climate add freq...</td>\n",
       "      <td>weather climate climate severity insurance com...</td>\n",
       "      <td>[weather, climate, climate, severity, insuranc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>cleaned_Travelers_TCFDReport2020.txt</td>\n",
       "      <td>2020</td>\n",
       "      <td>Traveler Cos TRV</td>\n",
       "      <td>Severe weather over the last two have\\nthe of ...</td>\n",
       "      <td>severe weather future climate climate add freq...</td>\n",
       "      <td>weather climate climate severity uncertainty i...</td>\n",
       "      <td>[weather, climate, climate, severity, uncertai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>cleaned_Travelers_TCFDReport2021.txt</td>\n",
       "      <td>2021</td>\n",
       "      <td>Traveler Cos TRV</td>\n",
       "      <td>additional uncertainty as to future and Climat...</td>\n",
       "      <td>additional uncertainty future climate governme...</td>\n",
       "      <td>uncertainty climate government catastrophe mod...</td>\n",
       "      <td>[uncertainty, climate, government, catastrophe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>cleaned_Travelers_TCFDReport2022.txt</td>\n",
       "      <td>2022</td>\n",
       "      <td>Traveler Cos TRV</td>\n",
       "      <td>of climate For example the frequency and or se...</td>\n",
       "      <td>climate example frequency severity hurricane t...</td>\n",
       "      <td>example frequency severity wildfire time perio...</td>\n",
       "      <td>[example, frequency, severity, wildfire, time,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>cleaned_Travelers_TCFDReport2023.txt</td>\n",
       "      <td>2023</td>\n",
       "      <td>Traveler Cos TRV</td>\n",
       "      <td>Severe weather over the last two have the\\nof ...</td>\n",
       "      <td>severe weather climate example frequency sever...</td>\n",
       "      <td>weather climate example frequency severity wil...</td>\n",
       "      <td>[weather, climate, example, frequency, severit...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               file_name  year      company_name  \\\n",
       "0  cleaned_sjp-tcfd-report-april2020.txt  2020   ST. JAMES place   \n",
       "1  cleaned_sjp-tcfd-report-april2021.txt  2021   ST. JAMES place   \n",
       "2       cleaned_SJP_TCFD_Report_2022.txt  2022   ST. JAMES place   \n",
       "3              cleaned_SJP_TCFD_2023.txt  2023   ST. JAMES place   \n",
       "4   cleaned_Travelers_TCFDReport2019.txt  2019  Traveler Cos TRV   \n",
       "5   cleaned_Travelers_TCFDReport2020.txt  2020  Traveler Cos TRV   \n",
       "6   cleaned_Travelers_TCFDReport2021.txt  2021  Traveler Cos TRV   \n",
       "7   cleaned_Travelers_TCFDReport2022.txt  2022  Traveler Cos TRV   \n",
       "8   cleaned_Travelers_TCFDReport2023.txt  2023  Traveler Cos TRV   \n",
       "\n",
       "                                                text  \\\n",
       "0  Committee s\\nof the Net\\nSt s Pace Report 2020...   \n",
       "1  46 to our 2021 report\\nto St s Pace Group s re...   \n",
       "2  change is fast becoming one\\nour It is a that ...   \n",
       "3  approach We are to our\\nwi have a effect over ...   \n",
       "4  Severe weather over the last two have\\nthe of ...   \n",
       "5  Severe weather over the last two have\\nthe of ...   \n",
       "6  additional uncertainty as to future and Climat...   \n",
       "7  of climate For example the frequency and or se...   \n",
       "8  Severe weather over the last two have the\\nof ...   \n",
       "\n",
       "                                          text_clean  \\\n",
       "0  Committee s Net St s Pace Report worth year ti...   \n",
       "1  report St s Pace Group s report wi take action...   \n",
       "2  change fast address Foster Director Business i...   \n",
       "3  approach wi effect time Maria Spooner Director...   \n",
       "4  severe weather future climate climate add freq...   \n",
       "5  severe weather future climate climate add freq...   \n",
       "6  additional uncertainty future climate governme...   \n",
       "7  climate example frequency severity hurricane t...   \n",
       "8  severe weather climate example frequency sever...   \n",
       "\n",
       "                                           text_noun  \\\n",
       "0  year time commitment term change business repo...   \n",
       "1  report action change business home page report...   \n",
       "2  address introduction statement business parent...   \n",
       "3  effect time business unit trust manager whist ...   \n",
       "4  weather climate climate severity insurance com...   \n",
       "5  weather climate climate severity uncertainty i...   \n",
       "6  uncertainty climate government catastrophe mod...   \n",
       "7  example frequency severity wildfire time perio...   \n",
       "8  weather climate example frequency severity wil...   \n",
       "\n",
       "                                               token  \n",
       "0  [year, time, commitment, term, change, busines...  \n",
       "1  [report, action, change, business, home, page,...  \n",
       "2  [address, introduction, statement, business, p...  \n",
       "3  [effect, time, business, unit, trust, manager,...  \n",
       "4  [weather, climate, climate, severity, insuranc...  \n",
       "5  [weather, climate, climate, severity, uncertai...  \n",
       "6  [uncertainty, climate, government, catastrophe...  \n",
       "7  [example, frequency, severity, wildfire, time,...  \n",
       "8  [weather, climate, example, frequency, severit...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load spaCy model\n",
    "nlp = spacy.load(\"en_core_web_sm\", disable=[\"parser\", \"ner\"])\n",
    "\n",
    "def clean_tokens_noun(text_series):\n",
    "    # Step 1: Convert text_series df to list\n",
    "    text_list = text_series.to_list()\n",
    "\n",
    "    # Step 2: Change the list to lower case\n",
    "    text_list = list(map(lambda x: x.lower(), text_list))\n",
    "\n",
    "    # Step 3: Remove whitespaces and trailing spaces\n",
    "    def remove_whitespace(text):\n",
    "        pattern = re.compile(r'\\s+')\n",
    "        without_whitespace = re.sub(pattern, ' ', text)\n",
    "        text = without_whitespace.replace('?', ' ? ').replace(')', ') ')\n",
    "        text = text.strip()\n",
    "        return text\n",
    "\n",
    "    text_list = list(map(lambda x: remove_whitespace(x), text_list))\n",
    "\n",
    "    # Create column for cleaned text_list\n",
    "    tokens, tmp_tokens = [], []\n",
    "    for text in tqdm(text_list):\n",
    "        tmp_tokens = [\n",
    "            token.lemma_\n",
    "            for token in nlp(text)\n",
    "            if not token.is_stop\n",
    "            and not token.like_num\n",
    "            and not token.is_punct\n",
    "            and token.is_alpha\n",
    "        ]\n",
    "        tokens.append(tmp_tokens)\n",
    "        tmp_tokens = []\n",
    "    return tokens\n",
    "\n",
    "# Use apply to get the token of the text_noun column\n",
    "df_horizontal['token'] = clean_tokens_noun(df_horizontal['text_noun'])\n",
    "print(len(df_horizontal))\n",
    "df_horizontal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>year</th>\n",
       "      <th>company_name</th>\n",
       "      <th>text</th>\n",
       "      <th>text_clean</th>\n",
       "      <th>text_noun</th>\n",
       "      <th>token</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cleaned_sjp-tcfd-report-april2020.txt</td>\n",
       "      <td>2020</td>\n",
       "      <td>ST. JAMES place</td>\n",
       "      <td>Committee s\\nof the Net\\nSt s Pace Report 2020...</td>\n",
       "      <td>Committee s Net St s Pace Report worth year ti...</td>\n",
       "      <td>year time commitment term change business repo...</td>\n",
       "      <td>[commitment, change, scope, change, pace, addi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cleaned_sjp-tcfd-report-april2021.txt</td>\n",
       "      <td>2021</td>\n",
       "      <td>ST. JAMES place</td>\n",
       "      <td>46 to our 2021 report\\nto St s Pace Group s re...</td>\n",
       "      <td>report St s Pace Group s report wi take action...</td>\n",
       "      <td>report action change business home page report...</td>\n",
       "      <td>[action, change, home, page, desire, head, cha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cleaned_SJP_TCFD_Report_2022.txt</td>\n",
       "      <td>2022</td>\n",
       "      <td>ST. JAMES place</td>\n",
       "      <td>change is fast becoming one\\nour It is a that ...</td>\n",
       "      <td>change fast address Foster Director Business i...</td>\n",
       "      <td>address introduction statement business parent...</td>\n",
       "      <td>[address, introduction, parent, company, unit,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cleaned_SJP_TCFD_2023.txt</td>\n",
       "      <td>2023</td>\n",
       "      <td>ST. JAMES place</td>\n",
       "      <td>approach We are to our\\nwi have a effect over ...</td>\n",
       "      <td>approach wi effect time Maria Spooner Director...</td>\n",
       "      <td>effect time business unit trust manager whist ...</td>\n",
       "      <td>[effect, unit, trust, manager, whist, company,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cleaned_Travelers_TCFDReport2019.txt</td>\n",
       "      <td>2019</td>\n",
       "      <td>Traveler Cos TRV</td>\n",
       "      <td>Severe weather over the last two have\\nthe of ...</td>\n",
       "      <td>severe weather future climate climate add freq...</td>\n",
       "      <td>weather climate climate severity insurance com...</td>\n",
       "      <td>[weather, climate, climate, severity, insuranc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>cleaned_Travelers_TCFDReport2020.txt</td>\n",
       "      <td>2020</td>\n",
       "      <td>Traveler Cos TRV</td>\n",
       "      <td>Severe weather over the last two have\\nthe of ...</td>\n",
       "      <td>severe weather future climate climate add freq...</td>\n",
       "      <td>weather climate climate severity uncertainty i...</td>\n",
       "      <td>[weather, climate, climate, severity, uncertai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>cleaned_Travelers_TCFDReport2021.txt</td>\n",
       "      <td>2021</td>\n",
       "      <td>Traveler Cos TRV</td>\n",
       "      <td>additional uncertainty as to future and Climat...</td>\n",
       "      <td>additional uncertainty future climate governme...</td>\n",
       "      <td>uncertainty climate government catastrophe mod...</td>\n",
       "      <td>[uncertainty, climate, government, catastrophe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>cleaned_Travelers_TCFDReport2022.txt</td>\n",
       "      <td>2022</td>\n",
       "      <td>Traveler Cos TRV</td>\n",
       "      <td>of climate For example the frequency and or se...</td>\n",
       "      <td>climate example frequency severity hurricane t...</td>\n",
       "      <td>example frequency severity wildfire time perio...</td>\n",
       "      <td>[example, frequency, severity, wildfire, clima...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>cleaned_Travelers_TCFDReport2023.txt</td>\n",
       "      <td>2023</td>\n",
       "      <td>Traveler Cos TRV</td>\n",
       "      <td>Severe weather over the last two have the\\nof ...</td>\n",
       "      <td>severe weather climate example frequency sever...</td>\n",
       "      <td>weather climate example frequency severity wil...</td>\n",
       "      <td>[weather, climate, example, frequency, severit...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               file_name  year      company_name  \\\n",
       "0  cleaned_sjp-tcfd-report-april2020.txt  2020   ST. JAMES place   \n",
       "1  cleaned_sjp-tcfd-report-april2021.txt  2021   ST. JAMES place   \n",
       "2       cleaned_SJP_TCFD_Report_2022.txt  2022   ST. JAMES place   \n",
       "3              cleaned_SJP_TCFD_2023.txt  2023   ST. JAMES place   \n",
       "4   cleaned_Travelers_TCFDReport2019.txt  2019  Traveler Cos TRV   \n",
       "5   cleaned_Travelers_TCFDReport2020.txt  2020  Traveler Cos TRV   \n",
       "6   cleaned_Travelers_TCFDReport2021.txt  2021  Traveler Cos TRV   \n",
       "7   cleaned_Travelers_TCFDReport2022.txt  2022  Traveler Cos TRV   \n",
       "8   cleaned_Travelers_TCFDReport2023.txt  2023  Traveler Cos TRV   \n",
       "\n",
       "                                                text  \\\n",
       "0  Committee s\\nof the Net\\nSt s Pace Report 2020...   \n",
       "1  46 to our 2021 report\\nto St s Pace Group s re...   \n",
       "2  change is fast becoming one\\nour It is a that ...   \n",
       "3  approach We are to our\\nwi have a effect over ...   \n",
       "4  Severe weather over the last two have\\nthe of ...   \n",
       "5  Severe weather over the last two have\\nthe of ...   \n",
       "6  additional uncertainty as to future and Climat...   \n",
       "7  of climate For example the frequency and or se...   \n",
       "8  Severe weather over the last two have the\\nof ...   \n",
       "\n",
       "                                          text_clean  \\\n",
       "0  Committee s Net St s Pace Report worth year ti...   \n",
       "1  report St s Pace Group s report wi take action...   \n",
       "2  change fast address Foster Director Business i...   \n",
       "3  approach wi effect time Maria Spooner Director...   \n",
       "4  severe weather future climate climate add freq...   \n",
       "5  severe weather future climate climate add freq...   \n",
       "6  additional uncertainty future climate governme...   \n",
       "7  climate example frequency severity hurricane t...   \n",
       "8  severe weather climate example frequency sever...   \n",
       "\n",
       "                                           text_noun  \\\n",
       "0  year time commitment term change business repo...   \n",
       "1  report action change business home page report...   \n",
       "2  address introduction statement business parent...   \n",
       "3  effect time business unit trust manager whist ...   \n",
       "4  weather climate climate severity insurance com...   \n",
       "5  weather climate climate severity uncertainty i...   \n",
       "6  uncertainty climate government catastrophe mod...   \n",
       "7  example frequency severity wildfire time perio...   \n",
       "8  weather climate example frequency severity wil...   \n",
       "\n",
       "                                               token  \n",
       "0  [commitment, change, scope, change, pace, addi...  \n",
       "1  [action, change, home, page, desire, head, cha...  \n",
       "2  [address, introduction, parent, company, unit,...  \n",
       "3  [effect, unit, trust, manager, whist, company,...  \n",
       "4  [weather, climate, climate, severity, insuranc...  \n",
       "5  [weather, climate, climate, severity, uncertai...  \n",
       "6  [uncertainty, climate, government, catastrophe...  \n",
       "7  [example, frequency, severity, wildfire, clima...  \n",
       "8  [weather, climate, example, frequency, severit...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop the words that are too general for earnings calls\n",
    "general_words = [\n",
    "    'lady', 'gentleman', 'presentation',\n",
    "    'question', 'answer', 'slide', 'mm', 'mm_mm', 'guy', 'sir', ' ', 'ytd', 'host_sir',\n",
    "    'bb', 'ty', 'word', 'year', 'quer', 'month', 'period', 'day', 'time', 'result',\n",
    "    'investor', 'week', 'update', 'business', 'lot', 'ratio', 'rate', 'quarter',\n",
    "    'number', 'point', 'term', 'thing', 'level', 'bit', 'sort', 'reason', 'management',\n",
    "    'fact', 'case', 'area', 'people', 'sense', 'item', 'issue', 'market', 'meeting',\n",
    "    'questions', 'answers', 'managements', 'discussion', 'section', 'presentation', \n",
    "    'speaker', 'participant', 'afternoon', 'morning', 'conference', 'today', 'lady', \n",
    "    'gentleman', 'presentation', 'question', 'answer', 'slide',\n",
    "    'mm', 'mm_mm', 'guy', 'sir', 'host_sir', 'bb', 'ty', 'word', 'year', 'quer',\n",
    "    'month', 'period', 'day', 'time', 'result', 'investor', 'week', 'update', 'business', 'lot', 'ratio', 'rate', 'quarter',\n",
    "    'number', 'point', 'term', 'thing', 'level', 'bit', 'sort', 'reason', 'management',\n",
    "    'fact', 'case', 'area', 'people', 'sense', 'item', 'issue', 'market', 'earnings',\n",
    "    'report', 'financial', 'results', 'quarterly', 'performance', 'guidance', 'statement',\n",
    "    'outlook', 'projection', 'profit', 'loss', 'revenue', 'sales', 'expense', 'income',\n",
    "    'cash', 'flow', 'margin', 'growth', 'decline', 'increase', 'decrease', 'forecast',\n",
    "    'expectation', 'trend', 'metric', 'indicator', 'shareholder', 'stock', 'price', 'value',\n",
    "    'equity', 'debt', 'asset', 'liability', 'balance', 'sheet', 'capital', 'investment',\n",
    "    'portfolio', 'dividend', 'yield', 'ratio', 'return', 'earnings', 'per', 'share', 'EPS',\n",
    "    'acquisition', 'merger', 'synergy', 'integration', 'strategy', 'execution', 'plan',\n",
    "    'objective', 'goal', 'target', 'vision', 'mission', 'operation', 'process', 'initiative',\n",
    "    'efficiency', 'optimization', 'innovation', 'technology', 'product', 'service', 'customer',\n",
    "    'client', 'market', 'segment', 'competition', 'competitor', 'industry', 'sector', 'environment',\n",
    "    'regulation', 'compliance', 'risk', 'opportunity', 'challenge', 'threat', 'advantage',\n",
    "    'disadvantage', 'strength', 'weakness', 'SWOT', 'analysis', 'review', 'summary',\n",
    "    'highlight', 'detail', 'report', 'note', 'comment', 'announcement', 'release', 'update','tcfd, Severe wind and hail n an a n an a, Hurricane n a n a, Winter storm n a n a'\n",
    "]\n",
    "\n",
    "# Apply the filtering to your DataFrame\n",
    "df_horizontal['token'] = df_horizontal['token'].apply(lambda x: [i for i in x if i not in general_words])\n",
    "\n",
    "# Display the updated DataFrame\n",
    "df_horizontal\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting and Cleaning Frequent Words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The script extracts the 50 most frequent words from the TCFD disclosures for each company and cleans the tokens by removing these frequent words. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  7.02it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.82it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.58it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.48it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.32it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.39it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.75it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.77it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.71it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>company_name</th>\n",
       "      <th>word_freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cleaned_sjp-tcfd-report-april2020.txt</td>\n",
       "      <td>ST. JAMES place</td>\n",
       "      <td>[(s, 73), (risk, 56), (pace, 53), (carbon, 45)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cleaned_sjp-tcfd-report-april2021.txt</td>\n",
       "      <td>ST. JAMES place</td>\n",
       "      <td>[(risk, 98), (s, 77), (business, 70), (carbon,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cleaned_SJP_TCFD_Report_2022.txt</td>\n",
       "      <td>ST. JAMES place</td>\n",
       "      <td>[(risk, 144), (s, 94), (investment, 93), (carb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cleaned_SJP_TCFD_2023.txt</td>\n",
       "      <td>ST. JAMES place</td>\n",
       "      <td>[(risk, 193), (s, 118), (investment, 111), (bu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cleaned_Travelers_TCFDReport2019.txt</td>\n",
       "      <td>Traveler Cos TRV</td>\n",
       "      <td>[(risk, 103), (climate, 100), (relate, 66), (c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>cleaned_Travelers_TCFDReport2020.txt</td>\n",
       "      <td>Traveler Cos TRV</td>\n",
       "      <td>[(climate, 103), (risk, 102), (relate, 67), (c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>cleaned_Travelers_TCFDReport2021.txt</td>\n",
       "      <td>Traveler Cos TRV</td>\n",
       "      <td>[(risk, 192), (climate, 185), (energy, 135), (...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>cleaned_Travelers_TCFDReport2022.txt</td>\n",
       "      <td>Traveler Cos TRV</td>\n",
       "      <td>[(risk, 198), (climate, 186), (energy, 130), (...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>cleaned_Travelers_TCFDReport2023.txt</td>\n",
       "      <td>Traveler Cos TRV</td>\n",
       "      <td>[(risk, 188), (climate, 169), (energy, 141), (...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               file_name      company_name  \\\n",
       "0  cleaned_sjp-tcfd-report-april2020.txt   ST. JAMES place   \n",
       "1  cleaned_sjp-tcfd-report-april2021.txt   ST. JAMES place   \n",
       "2       cleaned_SJP_TCFD_Report_2022.txt   ST. JAMES place   \n",
       "3              cleaned_SJP_TCFD_2023.txt   ST. JAMES place   \n",
       "4   cleaned_Travelers_TCFDReport2019.txt  Traveler Cos TRV   \n",
       "5   cleaned_Travelers_TCFDReport2020.txt  Traveler Cos TRV   \n",
       "6   cleaned_Travelers_TCFDReport2021.txt  Traveler Cos TRV   \n",
       "7   cleaned_Travelers_TCFDReport2022.txt  Traveler Cos TRV   \n",
       "8   cleaned_Travelers_TCFDReport2023.txt  Traveler Cos TRV   \n",
       "\n",
       "                                           word_freq  \n",
       "0  [(s, 73), (risk, 56), (pace, 53), (carbon, 45)...  \n",
       "1  [(risk, 98), (s, 77), (business, 70), (carbon,...  \n",
       "2  [(risk, 144), (s, 94), (investment, 93), (carb...  \n",
       "3  [(risk, 193), (s, 118), (investment, 111), (bu...  \n",
       "4  [(risk, 103), (climate, 100), (relate, 66), (c...  \n",
       "5  [(climate, 103), (risk, 102), (relate, 67), (c...  \n",
       "6  [(risk, 192), (climate, 185), (energy, 135), (...  \n",
       "7  [(risk, 198), (climate, 186), (energy, 130), (...  \n",
       "8  [(risk, 188), (climate, 169), (energy, 141), (...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize a list to hold the results\n",
    "most_frequent_words = []\n",
    "\n",
    "# Iterate over each unique company\n",
    "for company in df_horizontal['company_name'].unique():\n",
    "    # Filter the DataFrame for the current company\n",
    "    company_df = df_horizontal[df_horizontal['company_name'] == company]\n",
    "\n",
    "    # Iterate over each text file for the current company\n",
    "    for _, row in company_df.iterrows():\n",
    "        text = row['text']\n",
    "        file_name = row['file_name']\n",
    "\n",
    "        # Tokenize and clean the text\n",
    "        tokens = clean_tokens_noun(pd.Series([text]))[0]  # Using your existing function\n",
    "\n",
    "        # Calculate word frequency\n",
    "        word_freq = Counter(tokens).most_common(50)\n",
    "\n",
    "        # Append the results to the list\n",
    "        most_frequent_words.append([file_name, company, word_freq])\n",
    "\n",
    "# Create a DataFrame with the results\n",
    "frequent_words_df = pd.DataFrame(most_frequent_words, columns=['file_name', 'company_name', 'word_freq'])\n",
    "\n",
    "# Display the DataFrame\n",
    "frequent_words_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\dimi3\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n",
      "100%|██████████| 1/1 [00:00<00:00, 36.25it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 19.31it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 17.15it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 10.76it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 18.97it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 14.32it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  7.70it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  7.47it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  7.09it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 32.10it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 20.41it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 16.39it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 10.38it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 21.10it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 15.52it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  6.99it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  7.90it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  7.09it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>year</th>\n",
       "      <th>company_name</th>\n",
       "      <th>text</th>\n",
       "      <th>text_clean</th>\n",
       "      <th>text_noun</th>\n",
       "      <th>token</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cleaned_sjp-tcfd-report-april2020.txt</td>\n",
       "      <td>2020</td>\n",
       "      <td>ST. JAMES place</td>\n",
       "      <td>Committee s\\nof the Net\\nSt s Pace Report 2020...</td>\n",
       "      <td>Committee s Net St s Pace Report worth year ti...</td>\n",
       "      <td>year time commitment term change business repo...</td>\n",
       "      <td>[time, summary, overview, roe, key, considerat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cleaned_sjp-tcfd-report-april2021.txt</td>\n",
       "      <td>2021</td>\n",
       "      <td>ST. JAMES place</td>\n",
       "      <td>46 to our 2021 report\\nto St s Pace Group s re...</td>\n",
       "      <td>report St s Pace Group s report wi take action...</td>\n",
       "      <td>report action change business home page report...</td>\n",
       "      <td>[action, home, desire, head, summary, factor, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cleaned_SJP_TCFD_Report_2022.txt</td>\n",
       "      <td>2022</td>\n",
       "      <td>ST. JAMES place</td>\n",
       "      <td>change is fast becoming one\\nour It is a that ...</td>\n",
       "      <td>change fast address Foster Director Business i...</td>\n",
       "      <td>address introduction statement business parent...</td>\n",
       "      <td>[address, introduction, statement, parent, uni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cleaned_SJP_TCFD_2023.txt</td>\n",
       "      <td>2023</td>\n",
       "      <td>ST. JAMES place</td>\n",
       "      <td>approach We are to our\\nwi have a effect over ...</td>\n",
       "      <td>approach wi effect time Maria Spooner Director...</td>\n",
       "      <td>effect time business unit trust manager whist ...</td>\n",
       "      <td>[effect, unit, trust, singe, subsidiary, text,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cleaned_Travelers_TCFDReport2019.txt</td>\n",
       "      <td>2019</td>\n",
       "      <td>Traveler Cos TRV</td>\n",
       "      <td>Severe weather over the last two have\\nthe of ...</td>\n",
       "      <td>severe weather future climate climate add freq...</td>\n",
       "      <td>weather climate climate severity insurance com...</td>\n",
       "      <td>[casualty, role, organization, evaluation, ide...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>cleaned_Travelers_TCFDReport2020.txt</td>\n",
       "      <td>2020</td>\n",
       "      <td>Traveler Cos TRV</td>\n",
       "      <td>Severe weather over the last two have\\nthe of ...</td>\n",
       "      <td>severe weather future climate climate add freq...</td>\n",
       "      <td>weather climate climate severity uncertainty i...</td>\n",
       "      <td>[company, casualty, core, provide, price, prot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>cleaned_Travelers_TCFDReport2021.txt</td>\n",
       "      <td>2021</td>\n",
       "      <td>Traveler Cos TRV</td>\n",
       "      <td>additional uncertainty as to future and Climat...</td>\n",
       "      <td>additional uncertainty future climate governme...</td>\n",
       "      <td>uncertainty climate government catastrophe mod...</td>\n",
       "      <td>[government, experience, frequency, intensity,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>cleaned_Travelers_TCFDReport2022.txt</td>\n",
       "      <td>2022</td>\n",
       "      <td>Traveler Cos TRV</td>\n",
       "      <td>of climate For example the frequency and or se...</td>\n",
       "      <td>climate example frequency severity hurricane t...</td>\n",
       "      <td>example frequency severity wildfire time perio...</td>\n",
       "      <td>[frequency, severity, wildfire, period, severi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>cleaned_Travelers_TCFDReport2023.txt</td>\n",
       "      <td>2023</td>\n",
       "      <td>Traveler Cos TRV</td>\n",
       "      <td>Severe weather over the last two have the\\nof ...</td>\n",
       "      <td>severe weather climate example frequency sever...</td>\n",
       "      <td>weather climate example frequency severity wil...</td>\n",
       "      <td>[frequency, severity, wildfire, period, severi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               file_name  year      company_name  \\\n",
       "0  cleaned_sjp-tcfd-report-april2020.txt  2020   ST. JAMES place   \n",
       "1  cleaned_sjp-tcfd-report-april2021.txt  2021   ST. JAMES place   \n",
       "2       cleaned_SJP_TCFD_Report_2022.txt  2022   ST. JAMES place   \n",
       "3              cleaned_SJP_TCFD_2023.txt  2023   ST. JAMES place   \n",
       "4   cleaned_Travelers_TCFDReport2019.txt  2019  Traveler Cos TRV   \n",
       "5   cleaned_Travelers_TCFDReport2020.txt  2020  Traveler Cos TRV   \n",
       "6   cleaned_Travelers_TCFDReport2021.txt  2021  Traveler Cos TRV   \n",
       "7   cleaned_Travelers_TCFDReport2022.txt  2022  Traveler Cos TRV   \n",
       "8   cleaned_Travelers_TCFDReport2023.txt  2023  Traveler Cos TRV   \n",
       "\n",
       "                                                text  \\\n",
       "0  Committee s\\nof the Net\\nSt s Pace Report 2020...   \n",
       "1  46 to our 2021 report\\nto St s Pace Group s re...   \n",
       "2  change is fast becoming one\\nour It is a that ...   \n",
       "3  approach We are to our\\nwi have a effect over ...   \n",
       "4  Severe weather over the last two have\\nthe of ...   \n",
       "5  Severe weather over the last two have\\nthe of ...   \n",
       "6  additional uncertainty as to future and Climat...   \n",
       "7  of climate For example the frequency and or se...   \n",
       "8  Severe weather over the last two have the\\nof ...   \n",
       "\n",
       "                                          text_clean  \\\n",
       "0  Committee s Net St s Pace Report worth year ti...   \n",
       "1  report St s Pace Group s report wi take action...   \n",
       "2  change fast address Foster Director Business i...   \n",
       "3  approach wi effect time Maria Spooner Director...   \n",
       "4  severe weather future climate climate add freq...   \n",
       "5  severe weather future climate climate add freq...   \n",
       "6  additional uncertainty future climate governme...   \n",
       "7  climate example frequency severity hurricane t...   \n",
       "8  severe weather climate example frequency sever...   \n",
       "\n",
       "                                           text_noun  \\\n",
       "0  year time commitment term change business repo...   \n",
       "1  report action change business home page report...   \n",
       "2  address introduction statement business parent...   \n",
       "3  effect time business unit trust manager whist ...   \n",
       "4  weather climate climate severity insurance com...   \n",
       "5  weather climate climate severity uncertainty i...   \n",
       "6  uncertainty climate government catastrophe mod...   \n",
       "7  example frequency severity wildfire time perio...   \n",
       "8  weather climate example frequency severity wil...   \n",
       "\n",
       "                                               token  \n",
       "0  [time, summary, overview, roe, key, considerat...  \n",
       "1  [action, home, desire, head, summary, factor, ...  \n",
       "2  [address, introduction, statement, parent, uni...  \n",
       "3  [effect, unit, trust, singe, subsidiary, text,...  \n",
       "4  [casualty, role, organization, evaluation, ide...  \n",
       "5  [company, casualty, core, provide, price, prot...  \n",
       "6  [government, experience, frequency, intensity,...  \n",
       "7  [frequency, severity, wildfire, period, severi...  \n",
       "8  [frequency, severity, wildfire, period, severi...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make sure to download the words corpus if you haven't already\n",
    "nltk.download('words')\n",
    "\n",
    "# Initialize a list to hold the results\n",
    "most_frequent_words = []\n",
    "\n",
    "# Iterate over each unique company\n",
    "for company in df_horizontal['company_name'].unique():\n",
    "    # Filter the DataFrame for the current company\n",
    "    company_df = df_horizontal[df_horizontal['company_name'] == company]\n",
    "\n",
    "    # Iterate over each text file for the current company\n",
    "    for _, row in company_df.iterrows():\n",
    "        text = row['text_noun']\n",
    "        file_name = row['file_name']\n",
    "\n",
    "        # Tokenize and clean the text\n",
    "        tokens = clean_tokens_noun(pd.Series([text]))[0]  # Using your existing function\n",
    "\n",
    "        # Calculate word frequency\n",
    "        word_freq = Counter(tokens).most_common(50)\n",
    "\n",
    "        # Append the results to the list\n",
    "        most_frequent_words.append([file_name, company, word_freq])\n",
    "\n",
    "# Create a DataFrame with the results\n",
    "frequent_words_df = pd.DataFrame(most_frequent_words, columns=['file_name', 'company_name', 'word_freq'])\n",
    "\n",
    "# Remove the most frequent words from tokens\n",
    "cleaned_tokens = []\n",
    "\n",
    "for index, row in df_horizontal.iterrows():\n",
    "    text = row['text_noun']\n",
    "    tokens = clean_tokens_noun(pd.Series([text]))[0]\n",
    "\n",
    "    # Calculate word frequency for the current text\n",
    "    word_freq = Counter(tokens).most_common(50)\n",
    "    most_frequent_words = [word for word, freq in word_freq]\n",
    "\n",
    "    # Remove the most frequent words from tokens\n",
    "    tokens = [word for word in tokens if word not in most_frequent_words]\n",
    "\n",
    "    # Append the cleaned tokens to the list\n",
    "    cleaned_tokens.append(tokens)\n",
    "\n",
    "# Update the 'token' column with cleaned tokens\n",
    "df_horizontal['token'] = cleaned_tokens\n",
    "\n",
    "# Display the DataFrame\n",
    "df_horizontal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating and Saving the Final DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script processes the dataframe by splitting texts into chunks of about 150 words, treating each chunk as a paragraph. It groups data by company and applies the splits. The resulting final DataFrames are saved as separate CSV files for each company."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>date</th>\n",
       "      <th>company_name</th>\n",
       "      <th>token</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cleaned_sjp-tcfd-report-april2020.txt</td>\n",
       "      <td>2020</td>\n",
       "      <td>ST. JAMES place</td>\n",
       "      <td>[time, summary, overview, roe, key, considerat...</td>\n",
       "      <td>Committee s\\nof the Net\\nSt s Pace Report 2020...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cleaned_sjp-tcfd-report-april2021.txt</td>\n",
       "      <td>2021</td>\n",
       "      <td>ST. JAMES place</td>\n",
       "      <td>[action, home, desire, head, summary, factor, ...</td>\n",
       "      <td>46 to our 2021 report\\nto St s Pace Group s re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cleaned_SJP_TCFD_Report_2022.txt</td>\n",
       "      <td>2022</td>\n",
       "      <td>ST. JAMES place</td>\n",
       "      <td>[address, introduction, statement, parent, uni...</td>\n",
       "      <td>change is fast becoming one\\nour It is a that ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cleaned_SJP_TCFD_2023.txt</td>\n",
       "      <td>2023</td>\n",
       "      <td>ST. JAMES place</td>\n",
       "      <td>[effect, unit, trust, singe, subsidiary, text,...</td>\n",
       "      <td>approach We are to our\\nwi have a effect over ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cleaned_Travelers_TCFDReport2019.txt</td>\n",
       "      <td>2019</td>\n",
       "      <td>Traveler Cos TRV</td>\n",
       "      <td>[casualty, role, organization, evaluation, ide...</td>\n",
       "      <td>Severe weather over the last two have\\nthe of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>cleaned_Travelers_TCFDReport2020.txt</td>\n",
       "      <td>2020</td>\n",
       "      <td>Traveler Cos TRV</td>\n",
       "      <td>[company, casualty, core, provide, price, prot...</td>\n",
       "      <td>Severe weather over the last two have\\nthe of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>cleaned_Travelers_TCFDReport2021.txt</td>\n",
       "      <td>2021</td>\n",
       "      <td>Traveler Cos TRV</td>\n",
       "      <td>[government, experience, frequency, intensity,...</td>\n",
       "      <td>additional uncertainty as to future and Climat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>cleaned_Travelers_TCFDReport2022.txt</td>\n",
       "      <td>2022</td>\n",
       "      <td>Traveler Cos TRV</td>\n",
       "      <td>[frequency, severity, wildfire, period, severi...</td>\n",
       "      <td>of climate For example the frequency and or se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>cleaned_Travelers_TCFDReport2023.txt</td>\n",
       "      <td>2023</td>\n",
       "      <td>Traveler Cos TRV</td>\n",
       "      <td>[frequency, severity, wildfire, period, severi...</td>\n",
       "      <td>Severe weather over the last two have the\\nof ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               file_name  date      company_name  \\\n",
       "0  cleaned_sjp-tcfd-report-april2020.txt  2020   ST. JAMES place   \n",
       "1  cleaned_sjp-tcfd-report-april2021.txt  2021   ST. JAMES place   \n",
       "2       cleaned_SJP_TCFD_Report_2022.txt  2022   ST. JAMES place   \n",
       "3              cleaned_SJP_TCFD_2023.txt  2023   ST. JAMES place   \n",
       "4   cleaned_Travelers_TCFDReport2019.txt  2019  Traveler Cos TRV   \n",
       "5   cleaned_Travelers_TCFDReport2020.txt  2020  Traveler Cos TRV   \n",
       "6   cleaned_Travelers_TCFDReport2021.txt  2021  Traveler Cos TRV   \n",
       "7   cleaned_Travelers_TCFDReport2022.txt  2022  Traveler Cos TRV   \n",
       "8   cleaned_Travelers_TCFDReport2023.txt  2023  Traveler Cos TRV   \n",
       "\n",
       "                                               token  \\\n",
       "0  [time, summary, overview, roe, key, considerat...   \n",
       "1  [action, home, desire, head, summary, factor, ...   \n",
       "2  [address, introduction, statement, parent, uni...   \n",
       "3  [effect, unit, trust, singe, subsidiary, text,...   \n",
       "4  [casualty, role, organization, evaluation, ide...   \n",
       "5  [company, casualty, core, provide, price, prot...   \n",
       "6  [government, experience, frequency, intensity,...   \n",
       "7  [frequency, severity, wildfire, period, severi...   \n",
       "8  [frequency, severity, wildfire, period, severi...   \n",
       "\n",
       "                                                text  \n",
       "0  Committee s\\nof the Net\\nSt s Pace Report 2020...  \n",
       "1  46 to our 2021 report\\nto St s Pace Group s re...  \n",
       "2  change is fast becoming one\\nour It is a that ...  \n",
       "3  approach We are to our\\nwi have a effect over ...  \n",
       "4  Severe weather over the last two have\\nthe of ...  \n",
       "5  Severe weather over the last two have\\nthe of ...  \n",
       "6  additional uncertainty as to future and Climat...  \n",
       "7  of climate For example the frequency and or se...  \n",
       "8  Severe weather over the last two have the\\nof ...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the final DataFrame with the specified columns\n",
    "tcfd = df_horizontal[['file_name', 'year', 'company_name', 'token', 'text']]\n",
    "\n",
    "# Rename the columns according to your specifications\n",
    "tcfd.columns = ['file_name', 'date', 'company_name', 'token', 'text']\n",
    "\n",
    "# Display the DataFrame\n",
    "tcfd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the final DataFrame with the specified columns\n",
    "tcfd = df_horizontal[['file_name', 'year', 'company_name', 'token', 'text']]\n",
    "\n",
    "# Rename the columns according to your specifications\n",
    "tcfd.columns = ['file_name', 'date', 'company_name', 'token', 'paragraph']\n",
    "\n",
    "# Group by 'company_name' to create separate DataFrames for each company\n",
    "company_dfs = {}\n",
    "for company in tcfd['company_name'].unique():\n",
    "    company_df = tcfd[tcfd['company_name'] == company][['file_name', 'date', 'token', 'paragraph']]\n",
    "    company_name_cleaned = \"_\".join(company.split()[:2]).replace('(', '').replace(')', '').replace('.', '').replace(',', '').replace(\"'\", \"\") + '_tcfd_df'\n",
    "    company_dfs[company_name_cleaned] = company_df\n",
    "\n",
    "# Function to get DataFrame by company name\n",
    "def get_company_df(company_name):\n",
    "    company_name_cleaned = \"_\".join(company_name.split()[:2]).replace('(', '').replace(')', '').replace('.', '').replace(',', '').replace(\"'\", \"\") + '_tcfd_df'\n",
    "    return company_dfs.get(company_name_cleaned, None)\n",
    "\n",
    "# Function to split text into chunks of approximately 'chunk_size' words\n",
    "def split_into_chunks(text, chunk_size=150):\n",
    "    words = text.split()\n",
    "    chunks = [' '.join(words[i:i + chunk_size]) for i in range(0, len(words), chunk_size)]\n",
    "    return chunks\n",
    "\n",
    "# Function to split tokens into chunks corresponding to text chunks\n",
    "def split_tokens(tokens, chunk_size=150):\n",
    "    chunks = [tokens[i:i + chunk_size] for i in range(0, len(tokens), chunk_size)]\n",
    "    return chunks\n",
    "\n",
    "# Function to apply the split to the DataFrame and expand the rows\n",
    "def split_text_and_tokens_in_df(df, chunk_size=150):\n",
    "    rows = []\n",
    "    for _, row in df.iterrows():\n",
    "        text_chunks = split_into_chunks(row['paragraph'], chunk_size)\n",
    "        token_chunks = split_tokens(row['token'], chunk_size)\n",
    "        for text_chunk, token_chunk in zip(text_chunks, token_chunks):\n",
    "            new_row = row.copy()\n",
    "            new_row['paragraph'] = text_chunk\n",
    "            new_row['token'] = token_chunk\n",
    "            rows.append(new_row)\n",
    "    expanded_df = pd.DataFrame(rows)\n",
    "    expanded_df.reset_index(drop=True, inplace=True)\n",
    "    return expanded_df\n",
    "\n",
    "# Apply the function to split the text and tokens into chunks and expand the DataFrame for each company\n",
    "for company_name in company_dfs.keys():\n",
    "    company_dfs[company_name] = split_text_and_tokens_in_df(company_dfs[company_name])\n",
    "\n",
    "# Save each company's DataFrame to a CSV file\n",
    "output_dir = \"tcfd_company_csvs\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "for company_name, df in company_dfs.items():\n",
    "    csv_path = os.path.join(output_dir, f\"{company_name}.csv\")\n",
    "    df.to_csv(csv_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
